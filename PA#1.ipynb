{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA 1: Exploratory Analysis over Covid19 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Details\n",
    "\n",
    "Student Name and ID: \n",
    "\n",
    "Notes:\n",
    "When submitting, fill your name and ID in this cell. Note that this is a markdown cell!\n",
    "Do not make any changes in the dataset file and do not rename any '.csv' files.\n",
    "Rename your submission file to <b> 'yourLastName_Last4digitsofyourID_PA1.ipynb' </b>.\n",
    "Do not to forget to cite any external sources used by you.\n",
    "\n",
    "* [-5 points] if this note/rule is not abided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Details\n",
    "\n",
    "In this assignment, you will conduct a guided exploration over covid 19 dataset. You will learn and use some of the most common exploration/aggregation/descriptive operations. This should also help you learn most of the key functionalities in Pandas.\n",
    "\n",
    "You will also learn how to use visualization libraries to identify patterns in data that will help in your further data analysis. You will also explore most popular chart types and how to use different libraries and styles to make your visualizations more attractive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Details\n",
    "\n",
    "In this assignment, you will work on Covid 19 dataset. Specifically, you will work on covid.csv attached file with this project. The file covid.csv contains 35,156 rows and 10 columns. This dataset begins 01/22/2020, and runs upto 7/27/2020. It includes day to day country wise no. of cases which has County/State/Province level data. The columns of the data-set are:\n",
    "\n",
    "- Date - The day on which cases have been reported / recorded.\n",
    "- Country/Region - The country where these cases have been recorded.\n",
    "- Confirmed\tDeaths - The no. of deaths\n",
    "- Recovered\t- The no. of recovered cases.\n",
    "- Active - The no. of active cases.\n",
    "- New cases\t- The no. of new cases.\n",
    "- New deaths - The no. of new deaths.\t\n",
    "- New recovered - The no. of new recovered cases.\n",
    "- WHO Region - WHO operated regions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Python Packages\n",
    "You will use the packages imported below in this assignment. \n",
    "Do NOT import any new packages without confirming with the TA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special IPython command to prepare the notebook for matplotlib\n",
    "%matplotlib inline \n",
    "\n",
    "#Array processing\n",
    "import numpy as np\n",
    "#Data analysis, wrangling and common exploratory operations\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "#For visualization. Matplotlib for basic viz and seaborn for more stylish figures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Dataset\n",
    "The Python code below reads the Federal Emergencies and Disasters dataset into a Pandas data frame with the name df_data. \n",
    "For this code to work, the file 'database.csv' must be in the same folder as this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Task a: The csv file into a Pandas data frame: \n",
      " None\n",
      ">>Task b: The last 5 rows of the dataset are: \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "#2.5 points for both questions below.\n",
    "\n",
    "#read the csv file into a Pandas data frame\n",
    "print (\">>Task a: The csv file into a Pandas data frame: \\n\", None )\n",
    "\n",
    "#return the last 5 rows of the dataset\n",
    "print (\">>Task b: The last 5 rows of the dataset are: \\n\", None )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Statistical Exploratory Data Analysis\n",
    "Let us start with getting know the dataset. Your first task will be to get some basic information by using Pandas features.\n",
    "For each task below, look for a Pandas function to do the task.\n",
    "Replace None in each task with your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Task 1-a: Details of data frame are: \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# 2.5 points\n",
    "#Task 1-a: Print the details of the data frame (information such as number of rows,columns, name of columns, etc)\n",
    "print (\">>Task 1-a: Details of data frame are: \\n\", None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>Task 1-b: Number of rows:None and number of columns:None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.5 points\n",
    "#Task 1-b: Find the number of rows and columns in the data frame.\n",
    "num_rows = None\n",
    "num_cols = None\n",
    "print (\"\\n\\n>>Task 1-b: Number of rows:%s and number of columns:%s \\n\" % (num_rows, num_cols)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>Task 1-c: Total cases confirmed, deaths, and recovered are \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "#7.5 points\n",
    "#Task 1-c: Print the total cases confirmed, deaths, and recovered cases of each country with the given dataset.\n",
    "#The below variable holds data for all the unique countries, and their total - confirmed, deaths, and recovered cases.\n",
    "total_confirmed_deaths_recovered = None\n",
    "print (\"\\n\\n>>Task 1-c: Total cases confirmed, deaths, and recovered are \\n\", total_confirmed_deaths_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " >>Task 1-d: \n",
      " None\n",
      "\n",
      "\n",
      " >>Task 1-d: \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# 5 points for both questions below,\n",
    "\n",
    "#Task 1-d-i: Print top 10 worst affected countries with confirmed cases.\n",
    "top_confirmed_ten_countries  = None\n",
    "print (\"\\n\\n >>Task 1-d: \\n\", None)\n",
    "\n",
    "#Task 1-d-ii: Print top 5 worst affected countries with death cases.\n",
    "top_death_five_countries  = None\n",
    "print (\"\\n\\n >>Task 1-d: \\n\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Aggregation & Filtering & Rank\n",
    "In this task, we will perform some very high level aggregation and filtering operations. \n",
    "Then, we will apply ranking on the results for some tasks. \n",
    "Pandas has a convenient and powerful syntax for aggregation, filtering, and ranking. \n",
    "DO NOT write a for loop. Pandas has built-in functions for all tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Task 2-a:  The countries that has had more than a total of 2 hundred thousand confirmed cases are: \n",
      "None\n",
      "\n",
      "\n",
      ">>Task 2-b: The total number of confirmed, recovered, and death cases for each WHO region are: \n",
      "None\n",
      "\n",
      "\n",
      ">>Task 2-c: The top 5 poorly performing countries, in the order of confirmed, deaths, and recovered cases.s are: \n",
      "None\n",
      "\n",
      "\n",
      ">>Task 2-d: The top 5 poorly performing WHO regions, in the order of confirmed, deaths, and recovered cases are: \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 8 points\n",
    "#Task 2-a: Find out the countries that has had more than a total of 2 hundred thousand confirmed cases.\n",
    "confirmed_greater_than_200K = None\n",
    "print (\">>Task 2-a:  The countries that has had more than a total of 2 hundred thousand confirmed cases are: \\n%s\" % (confirmed_greater_than_200K))\n",
    "\n",
    "# 8 points\n",
    "#Task 2-b: Find out the total number of confirmed, recovered, and death cases for each WHO region.\n",
    "total_cases_whoregion = None\n",
    "print (\"\\n\\n>>Task 2-b: The total number of confirmed, recovered, and death cases for each WHO region are: \\n%s\" % (total_cases_whoregion))\n",
    "\n",
    "# 7 points\n",
    "#Task 2-c: Find out the top 5 poorly performing countries, in the order of confirmed, deaths, and recovered cases.\n",
    "top5_poorlyperforming=None\n",
    "print (\"\\n\\n>>Task 2-c: The top 5 poorly performing countries, in the order of confirmed, deaths, and recovered cases.s are: \\n%s\" % (top5_poorlyperforming))\n",
    "\n",
    "# 7 points\n",
    "#Task 2-d: Find out the top 5 poorly performing WHO regions, in the order of confirmed, deaths, and recovered cases.\n",
    "top5_disasters=None\n",
    "print (\"\\n\\n>>Task 2-d: The top 5 poorly performing WHO regions, in the order of confirmed, deaths, and recovered cases are: \\n%s\" % (top5_disasters))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Visualization\n",
    "In this task, you will perform a number of visualization tasks to get some intuition about the data. Visualization is a key component of exploration. You can choose to use either Matplotlib or Seaborn for plotting. The default figures generated from Matplotlib might look a bit ugly. So you might want to try Seaborn to get better figures. Seaborn has a variety of styles. Feel free to experiment with them and choose the one you like. We have earmarked 10 points for the aesthetics of your visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale = 1.3)\n",
    "\n",
    "# 15 points\n",
    "# Task 3-a: Plot the graph for the top 10 poorly performing countries, over 7 months of data provided \n",
    "# Think of a way to nicely visualize all the countries. \n",
    "#########################begin code for Task 3-a\n",
    "#########################end code for Task 3-a\n",
    "\n",
    "# 15 points\n",
    "# Task 3-b: Plot a pie-chart for the top 3 poorly performing WHO regions, over 7 months of data provided \n",
    "#########################begin code for Task 3-b \n",
    "#########################end code for Task 3-b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Interesting Information.\n",
    "Find out an 'interesting' information from the dataset. Create a visualization for it and explain in a few lines your reasoning. \n",
    "\n",
    "This task is worth 10 points. Your result will be judged based on the uniqueness and quality of your work (having a meaningful result and an aesthetic visualization). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################begin code for Task 4\n",
    "\n",
    "#########################end code for Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: WEKA\n",
    "\n",
    "You have to use WEKA,\n",
    "* This task is worth 10 points.\n",
    "* This task is different from the above tasks attached.\n",
    "* You have to work on disaster.csv dataset attached in the same directory as the file.\n",
    "* Find out how to convert the used dataset in weka format \n",
    "* Convert it \n",
    "* use the weka visualizer to produce some graphs.\n",
    "* Write down observations, on the images you are going to attach with the submission.\n",
    "* You must attach atleast 5 different observations alongwith your submission.\n",
    "\n",
    "\n",
    "In this dataset, you will work on 63 years of Federal Disasters dataset. The file database.csv contains 46,184 rows and 14 columns. This dataset begins with the year 1953, and runs up to the year 2017. Each row corresponds to an emergency declared by the president due to a natural disaster all around the US. The columns of the data-set are:\n",
    "\n",
    "* Declaration Number - Unique number for each emergency declared\n",
    "* Declaration Type - Type of declaration\n",
    "* Declaration Date - Date of declaration\n",
    "* State - State affected\n",
    "* County - County affected\n",
    "* Disaster Type\n",
    "* Disaster Title\n",
    "* Start Date - The date event started\n",
    "* End Date - The date event ended\n",
    "* Close Date - End of Declaration\n",
    "* Individual Assistance Program - Whether IAP was provided or not?\n",
    "* Individuals & Households Program - Whether IHP was provided or not?\n",
    "* Public Assistance Program - Whether PAP was provided or not?\n",
    "* Hazard Mitigation Program - Whether HMP was provided or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################begin code for Task 5\n",
    "# Goto weka tools and open disaster.csv file in arff viewer.\n",
    "# If you find any problems in the dataset, you can pre-process data to avoid any such case as per your obersvations,\n",
    "# and mention it here.\n",
    "# and finally you can save it as arff file\n",
    "# Write down observations, on the images you are going to attach with the submission.\n",
    "\n",
    "\n",
    "### For submission, the arff file has to be submitted alongwith 5 graphical observations in a folder with extensions .png, .jpg\n",
    "### or can provide a compiled set of images in a word or pdf.\n",
    "#########################end code for Task 5 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
